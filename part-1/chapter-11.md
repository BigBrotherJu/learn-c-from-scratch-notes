# 11. 排序与查找

## 11.1 算法的概念

- 算法是什么

  算法（Algorithm）是将一组输入转化成一组输出的一系列计算步骤，其中每个步骤必须能在有限时间内完成。

- 算法解决的是一类计算问题，不是一个问题

  算法是用来解决一类计算问题的，注意是一类问题，而不是一个特定的问题。

  由于算法是用来解决一类问题的，它必须能够正确地解决这一类问题中的任何一个实例，这个算法才是正确的。

- 不正确的算法

  不正确的算法有两种可能，一是对于该问题的某些输入，该算法会无限计算下去，不会终止；二是对于该问题的某些输入，该算法终止时输出的是错误的结果。

- 不正确的算法有时候也是有用的

  有时候不正确的算法也是有用的，如果对于某个问题寻求正确的算法很困难，而某个不正确的算法可以在有限时间内终止，并且能把误差控制在一定范围内，那么这样的算法也是有实际意义的。

  例如有时候寻找最优解的开销很大，往往会选择能给出次优解的算法。

## 11.2 插入排序

- 理解循环结构的算法：loop invariant 和数学归纳法

  我们可以借助Loop Invariant的概念和数学归纳法来理解循环结构的算法。

  假如某个判断条件满足以下三条准则，它就称为Loop Invariant：

  1.  第一次执行循环体之前该判断条件为真。

  2.  如果“第N-1次循环之后（或者说第N次循环之前）该判断条件为真”这个前提可以成立，那么就有办法证明第N次循环之后该判断条件仍为真。

  3.  如果在所有循环结束后该判断条件为真，那么就有办法证明该算法正确地解决了问题。

  只要我们找到这个Loop Invariant，就可以证明一个循环结构的算法是正确的。

- 证明插入排序算法是正确的

  上述插入排序算法的Loop Invariant是这样的判断条件：第j次循环之前，子序列a[0..j-1]是排好序的。

  在上面的打印结果中，我把子序列a[0..j-1]加粗表示。

  下面我们验证一下Loop Invariant的三条准则：

  1.  第一次执行循环之前，j=1，子序列a[0..j-1]只有一个元素a[0]，只有一个元素的序列显然是排好序的。

  2.  第j次循环之前，如果“子序列a[0..j-1]是排好序的”这个前提成立，现在要把key=a[j]插进去，按照该算法的步骤，把a[j-1]、a[j-2]、a[j-3]等比key大的元素都依次往后移一个，直到找到合适的位置将key插入，就能证明循环结束时子序列a[0..j]是排好序的。就像插扑克牌一样，“手中已有的牌是排好序的”这个前提很重要，如果没有这个前提，就不能证明再插一张牌之后也是排好序的。

  3.  当循环结束时，j=LEN，如果“子序列a[0..j-1]是排好序的”这个前提成立，那就是说a[0..LEN-1]是排好序的，也就是说整个数组a的LEN个元素都排好序了。

  可见，有了这三条，就可以用数学归纳法证明这个循环是正确的。这和第5.3节证明递归程序正确性的思路是一致的，这里的第一条就相当于递归的Base Case，第二条就相当于递归的递推关系。这再次说明了递归和循环是等价的。

## 11.3 算法的时间复杂度分析

- 算法的时间复杂度可以评价算法的好坏

  解决同一个问题可以有很多种算法，比较评价算法的好坏，一个重要的标准就是算法的时间复杂度。

- 指令的执行时间

  受内存管理机制的影响，指令的执行时间不一定是常数，但执行时间的上界（Upper Bound）肯定是常数，我们这里假设语句的执行时间是常数只是一个粗略估计。

- 三种情况

  - 最好情况

    在最好情况下，数组a的原始数据已经排好序了，while循环一次也不执行，总的执行时间是(c1+c2+c5)×n-(c1+c2+c5)，可以表示成an+b的形式，是n的线性函数（Linear Function）。

  - 最坏情况和平均情况

    那么在最坏情况（Worst Case）下又如何呢？所谓最坏情况是指数组a的原始数据正好是从大到小排好序的，请读者想一想为什么这是最坏情况，然后把上式中的m替换掉算一下执行时间是多少。

    数组a的原始数据属于最好和最坏情况的都比较少见，如果原始数据是随机的，可称为平均情况（Average Case）。如果原始数据是随机的，那么每次循环将已排序的子序列a[1..j-1]与新插入的元素key相比较，子序列中平均都有一半的元素比key大而另一半比key小，请读者把上式中的m替换掉算一下执行时间是多少。

    最后的结论应该是：在最坏情况和平均情况下，总的执行时间都可以表示成an<sup>2</sup>+bn+c的形式，是n的二次函数（Quadratic Function）。

  - 我们更关心最坏情况而不是最好情况

    在分析算法的时间复杂度时，我们更关心最坏情况而不是最好情况，理由如下：

    1.  最坏情况给出了算法执行时间的上界，我们可以确信，无论给什么输入，算法的执行时间都不会超过这个上界，这样为比较和分析提供了便利。

    2.  对于某些算法，最坏情况是最常发生的情况，例如在数据库中查找某个信息的算法，最坏情况就是数据库中根本不存在该信息，都找遍了也没有，而某些应用场合经常要查找一个信息在数据库中存在不存在。

- n 的最高次指数是决定因素

  比较两个多项式a<sub>1</sub>n+b<sub>1</sub>和a<sub>2</sub>n<sup>2</sup>+b<sub>2</sub>n+c<sub>2</sub>的值（n取正整数）可以得出结论：n的最高次指数是最主要的决定因素，常数项、低次幂项和系数都是次要的。

  比如100n+1和n<sup>2</sup>+1，虽然后者的系数小，当n较小时前者的值较大，但是当n>100时，后者的值就远远大于前者了。

  如果同一个问题可以用两种算法解决，其中一种算法的时间复杂度为线性函数，另一种算法的时间复杂度为二次函数，当问题的输入长度n足够大时，前者明显优于后者。

- 更粗略的方法表示算法时间复杂度：Θ-notation

  因此我们可以用一种更粗略的方式表示算法的时间复杂度，把系数和低次幂项都省去，线性函数记作Θ(n)，二次函数记作Θ(n<sup>2</sup>)。

  Θ(g(n))表示和g(n)同一量级的一类函数，例如所有的二次函数f(n)都和g(n)=n<sup>2</sup>属于同一量级，都可以用Θ(n<sup>2</sup>)来表示，甚至有些不是二次函数的也和n<sup>2</sup>属于同一量级，例如2n<sup>2</sup>+3lgn。

  如果可以找到两个正的常数c<sub>1</sub>和c<sub>2</sub>，使得n足够大的时候（也就是n≥n<sub>0</sub>的时候）f(n)总是夹在c<sub>1</sub>g(n)和c<sub>2</sub>g(n)之间，就说f(n)和g(n)是同一量级的，f(n)就可以用Θ(g(n))来表示。

- 常见的时间复杂度函数

  几种常见的时间复杂度函数按数量级从小到大的顺序依次是：Θ(lgn)，Θ(sqrt(n))，Θ(n)，Θ(nlgn)，Θ(n<sup>2</sup>)，Θ(n<sup>3</sup>)，Θ(2<sup>n</sup>)，Θ(n!)。

  其中，lgn通常表示以10为底n的对数，但是对于Θ-notation来说，Θ(lgn)和Θ(log2n)并无区别（想一想这是为什么），在算法分析中lgn通常表示以2为底n的对数。

  可是什么算法的时间复杂度里会出现lgn呢？回顾插入排序的时间复杂度分析，无非是循环体的执行时间乘以循环次数，只有加和乘运算，怎么会出来lg呢？下一节归并排序的时间复杂度里面就有lg，请读者留心lg运算是从哪出来的。

- Big-O notation

  除了Θ-notation之外，表示算法的时间复杂度常用的还有一种Big-O notation。

  我们知道插入排序在最坏情况和平均情况下时间复杂度是Θ(n<sup>2</sup>)，在最好情况下是Θ(n)，数量级比Θ(n<sup>2</sup>)要小，那么总结起来在各种情况下插入排序的时间复杂度是O(n<sup>2</sup>)。

  Θ的含义和“等于”类似，而大O的含义和“小于等于”类似。

## 11.4 归并排序

- 增量式和分而治之

  插入排序算法采取增量式（Incremental）的策略解决问题，每次添一个元素到已排序的子序列中，逐渐将整个数组排序完毕，它的时间复杂度是O(n<sup>2</sup>)。

  下面介绍另一种典型的排序算法——归并排序，它采取分而治之（Divide-and-Conquer）的策略，时间复杂度是Θ(nlgn)。

## 11.5 线性查找

## 11.6 折半查找

- 借助 Loop Invariant 证明循环的正确性

- Design by Contract：precondition、对 invariant 进行 maintenance、postcondition

  从更普遍的意义上说，函数的调用者（Caller）和函数的实现者（Callee，被调用者）之间订立了一个契约（Contract）。

  在调用函数之前，Caller要为Callee提供某些条件，比如确保a是排好序的，确保a[start..end]都是有效的数组元素而没有访问越界，这称为Precondition，然后Callee对一些Invariant进行维护（Maintenance），这些Invariant保证了Callee在函数返回时能够对Caller尽到某些义务，比如确保“如果number在数组a中存在，一定能找出来并返回它的位置；如果number在数组a中不存在，一定能返回-1”，这称为Postcondition。

  如果每个函数的文档都非常清楚地记录了Precondition、Maintenance和Postcondition是什么，那么每个函数都可以独立编写和测试，整个系统就会易于维护。

  这种编程思想是由Eiffel语言的设计者Bertrand Meyer提出来的，称为Design by Contract（DbC）。

- 测试一个函数要把三方面都测试到

  测试一个函数是否正确需要把Precondition、Maintenance和Postcondition这三方面都测试到，比如binarysearch这个函数，即使它写得非常正确，既维护了Invariant也保证了Postcondition，如果调用它的Caller没有保证Precondition，最后的结果也还是错的。

  我们编写几个测试用的Predicate函数，然后把相关的测试插入到binarysearch函数中。

- assert 宏定义

  assert是头文件assert.h中的一个宏定义，执行到assert(is_sorted())这句时，如果is_sorted()返回值为真，则当什么事都没发生过，继续往下执行；如果is_sorted()返回值为假（例如改变数组的排列顺序），则报错退出程序。

  在代码中适当的地方使用断言（Assertion）可以有效地帮助我们测试程序。

- 如何测试测试函数

  也许有人会问：我们用几个测试函数来测试binarysearch，那么这几个测试函数又用什么来测试呢？

  在实际工作中我们要测试的代码绝不会像binarysearch这么简单，而我们编写的测试函数往往都很简单，比较容易保证正确性，也就是用简单的、不容易出错的代码去测试复杂的、容易出错的代码。

- 禁用 assert 宏定义

  - 定义 NDEBUG 宏

    测试代码只在开发和调试时有用，如果正式发布（Release）的软件也要运行这些测试代码就会严重影响性能了。

    如果在包含assert.h之前定义一个NDEBUG宏（表示No Debug），就可以禁用assert.h中的assert宏定义，这样代码中的所有assert测试都不起作用了：

    ``` c
    #define NDEBUG
    #include <stdio.h>
    #include <assert.h>
    ```

    注意NDEBUG和我们以前使用的宏定义有点不同，例如#define N 20将N定义为20，在预处理时把代码中所有的标识符N替换成20，而#define NDEBUG**把NDEBUG定义为空**，在预处理时把代码中所有的标识符NDEBUG替换成空。这样的宏定义主要是为了用#ifdef等预处理指示测试它定义过没有，而不是为了做替换，所以定义成什么值都无所谓，一般定义成空就足够了。

  - 编译时加上 -DNDEBUG

    还有另一种办法，不必修改源文件，在编译命令行加上选项-DNDEBUG就相当于在源文件开头定义了NDEBUG宏。

    宏定义和预处理到第20章再详细解释，在第20.4节将给出assert.h的一种实现。
